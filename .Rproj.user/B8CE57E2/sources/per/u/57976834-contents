df<-readxl::read_excel("spambase.xlsx")

n=dim(df)[1]
set.seed(12345)
id<-sample(1:n,floor(n*0.5))
t1<-df[id,]
t2<-df[-id,]

logfit<-glm(Spam~.,data=t1,family = binomial(link = "logit"))

miser<-function(X,X1){
  n<-length(X)
  return(1-sum(diag(table(X,X1)))/n) #misclassification error function
}

y1<-predict.glm(logfit,t1,type="response")
y2<-predict.glm(logfit,t2,type="response")

y11<-ifelse(y1>0.5,1,0)
y22<-ifelse(y2>0.5,1,0)

table(t1$Spam,y11,dnn=c("true","predictions"))

table(t2$Spam,y22,dnn=c("true","predictions"))

e1<-mean(t1$Spam!=y11)
a1<-mean(t1$Spam==y11)

cat("=================================================================\n",
"The accuracy and the misclassification error for train data are :",e1,a1)


mean(t2$Spam==y22)

mean(t2$Spam!=y22)



library(kknn)
t1$Spam<-as.factor(t1$Spam)

knn.fit1<-kknn(Spam~.,t1,t1,k=30)
table(t1$Spam,knn.fit1$fitted.values)

mean(t1$Spam==knn.fit1$fitted.values)


t2$Spam<-as.factor(t2$Spam)

knn.fit2<-kknn(Spam~.,t1,t2,k=30)
table(t2$Spam,knn.fit2$fitted.values)

mean(t2$Spam==knn.fit2$fitted.values)
1-mean(t2$Spam==knn.fit2$fitted.values)






tec<-readxl::read_excel("tecator.xlsx")


plot(tec$Moisture,tec$Protein,col = ifelse(tec$Moisture>55&tec$Moisture<78&tec$Protein<14, "red", "blue"),pch=13)
abline(lm(Protein ~ Moisture,data=tec))


n1<-dim(tec)[1]
set.seed(12345)
indx<-sample(1:n1,floor(n1*0.5))
tr1<-tec[indx,]
te1<-tec[-indx,]


mat1<-matrix(0,nrow=6,ncol = 2)

for (i in 1:6){
  model<-lm(Moisture~poly(Protein,i),data=tr1)
  pred1<-predict(model,tr1,type="response")
  pred2<-predict(model,te1,type="response")
  
  mse<-function(true,preds){
    mean((true-preds)^2)
  }
  
  mat1[i,1]<-mse(tr1$Moisture,pred1)
  mat1[i,2]<-mse(te1$Moisture,pred2)

}

colnames(mat1)<-c("train mse","valid mse")

plot(seq(1,6),mat1[,1],col="blue",pch=19,ylim=c(31,35))
lines(seq(1,6),mat1[,1],col="blue")
points(seq(1,6),mat1[,2],col="red",pch=19)
lines(seq(1,6),mat1[,2],col="red")
legend(4,33,legend=c("MSE train","MSE test"),col=c("blue","red"),lty=1)



library(MASS)
tec_fat<-tec[!names(tec)%in%c("Sample","Protein","Moisture")]
mod.fit<-lm(Fat~.,data=tec_fat)
step.model<-stepAIC(mod.fit,direction = "both",trace=F)

length(step.model$coefficients)

(mean(step.model$residuals^2))
(mean((step.model$fitted.values-tec_fat$Fat)^2))



library(glmnet)
cov<-scale(tec_fat[!names(tec_fat)%in%c("Fat")])
res<-scale(tec_fat$Fat)
ridge.mod<-glmnet(as.matrix(cov),res,family = "gaussian",alpha = 0)

plot(ridge.mod, xvar = c("lambda"), label = T)



lasso.mod<-glmnet(as.matrix(cov),res,family = "gaussian",alpha = 1)

plot(lasso.mod, xvar = c("lambda"), label = T)



set.seed(12345)
lasso.cv<-cv.glmnet(as.matrix(cov),res,family = "gaussian",alpha = 1,lambda=seq(0,2,0.0001),type.measure = "mse")

lasso.cv$lambda.min
lasso.cv$lambda.1se

c<-coef(lasso.cv,mod="lambda.1se")

length(c[which(c!=0)])

lasso.cv.pred<-predict(lasso.cv,newx = as.matrix(cov))
mean((lasso.cv.pred-res)^2)





spam.data<-read.csv2("spambase.csv")
spam.data$Spam<-as.factor(spam.data$Spam)

n2=dim(spam.data)[1]
set.seed(12345)
id=sample(1:n2, floor(n2*2/3))
trainS=spam.data[id,]
testS=spam.data[-id,]


library(mboost)
library(randomForest)



steps<-seq(10,100,10)
e.train.ada<-double(10)
e.test.ada<-double(10)


for (i in steps){
  ada.model<-blackboost(Spam~.,data=trainS,family=AdaExp(),control=boost_control(mstop=i))
  
  error_func<-function(X){
     predictions<-predict(ada.model,X,type="class")
     error<-mean(X$Spam!=predictions)
     error
   }
  
  e.train.ada[which(steps==i)]<-error_func(trainS)
  e.test.ada[which(steps==i)]<-error_func(testS) 
   
}

ada.matrix<-cbind(e.train.ada,e.test.ada)

par(mfrow=c(1,2))

plot(steps,ada.matrix[,1],type="l",col="red",main="Ada Boost train/test error rates",
     ylab="misclassification error",cex.main=0.9)
lines(steps,ada.matrix[,2],type="l",col="blue")
#plots of accuracy for train and test
plot(steps,(1-ada.matrix[,1]),type="l",col="red",main="Ada Boost train/test accuarcy rates",
     ylab = "accuracy",cex.main=0.9)
lines(steps,(1-ada.matrix[,2]),type="l",col="blue")



set.seed(12345)
e.train.rndf<-double(10)
e.test.rndf<-double(10)


for (i in steps){
  rndf.model<-randomForest(Spam~.,data=trainS,ntree=i)
  
  error_func<-function(X){
    predictions<-predict(rndf.model,X,type="class")
    error<-mean(X$Spam!=predictions)
    error
  }
  
  e.train.rndf[which(steps==i)]<-error_func(trainS)
  e.test.rndf[which(steps==i)]<-error_func(testS) 
  
}


rndf.matrix<-cbind(e.train.rndf,e.test.rndf)

par(mfrow=c(1,2))

plot(steps,rndf.matrix[,1],type="l",col="red",main="Ada Boost train/test error rates",
     ylab="misclassification error",cex.main=0.9,ylim = c(0,0.07))
lines(steps,rndf.matrix[,2],type="l",col="blue")
#plots of accuracy for train and test
plot(steps,(1-rndf.matrix[,1]),type="l",col="red",main="Ada Boost train/test accuarcy rates",
     ylab = "accuracy",cex.main=0.9,ylim=c(0.94,1))
lines(steps,(1-rndf.matrix[,2]),type="l",col="blue")



credit<-readxl::read_excel("creditscoring.xls")
credit<-as.data.frame(credit)
credit$good_bad<-as.factor(credit$good_bad)

n3=dim(credit)[1]
set.seed(12345)
idx=sample(1:n3, floor(n3*0.5))
train.score=credit[idx,]
id1=setdiff(1:n3, idx)
set.seed(12345)
id2=sample(id1, floor(n3*0.25))
valid=credit[id2,]
id3=setdiff(id1,id2)
test.score=credit[id3,]



library(tree)


dev_tree<-tree(good_bad~.,data=train.score,split = "deviance")
gini_tree<-tree(good_bad~.,data=train.score,split="gini")


pred_error<-function(X,model.fit){
  predictions<-predict(model.fit,X,type="class")
  error<-mean(predictions!=X$good_bad)
  return(error)
}


dev_train_e<-pred_error(train.score,dev_tree)
dev_test_e<-pred_error(test.score,dev_tree)

gini_train_e<-pred_error(train.score,gini_tree)
gini_test_e<-pred_error(test.score,gini_tree)

errors_trees<-cbind(c(dev_train_e,dev_test_e),c(gini_train_e,gini_test_e))
colnames(errors_trees)<-c("deviance","gini")


plot(1:nrow(errors_trees),errors_trees[,1],col="blue",pch=19,ylim=c(0.20,0.38),type="b")
points(seq(1,2,1),errors_trees[,2],col="red",pch=19,type="b")
legend(1,0.34,legend=c("deviance","gini"),col=c("blue","red"),lty=1)


fit<-tree(good_bad~.,data=train.score)
trainScore=rep(0,12)
testScore=rep(0,12)

for(i in 2:12) {
  prunedTree=prune.tree(fit,best=i)
  pred=predict(prunedTree, newdata=valid,
               type="tree")
  trainScore[i]=deviance(prunedTree)
  testScore[i]=deviance(pred)
}


plot(2:12, trainScore[2:12], type="b", col="red",
     ylim=c(200,700))
points(2:12, testScore[2:12], type="b", col="blue")



ftree<-prune.tree(fit,best = 4)

summary(ftree)
plot(ftree)
text(ftree,cex=.90)

pred_ftree_train<-pred_error(train.score,ftree)
pred_ftree_test<-pred_error(test.score,ftree)

(pred_ftree_train)
(pred_ftree_test)



library(MASS)
library(e1071)

naive.fit<-naiveBayes(good_bad~.,data=train.score)
preds_naive_tr<-predict(naive.fit,train.score,type="class")
preds_naive_te<-predict(naive.fit,test.score,type="class")

table(train.score$good_bad,preds_naive_tr)
table(test.score$good_bad,preds_naive_te)

(pred_error(train.score,naive.fit))
(pred_error(test.score,naive.fit))

p<-seq(0.05,0.95,0.05)

naive_good<-predict(naive.fit,test.score,type="raw")[,2]
mat<-vector()

for (i in p){
  pred_naive<-ifelse(naive_good>i,1,0)
  t<-table(test.score$good_bad,pred_naive)
  tpr<-t[1]/(t[1]+t[3])
  fpr<-t[2]/(t[2]+t[4])
  mat<-rbind(mat,c(tpr,fpr))
  
}
colnames(mat)<-c("tpr","fpr")


naive_good<-predict(naive.fit,test.score,type="raw")[,2]
mat<-vector()

for (i in p){
  pred_naive<-ifelse(naive_good>i,1,0)
  t<-table(test.score$good_bad,pred_naive)
  tpr<-t[1]/(t[1]+t[3])
  fpr<-t[2]/(t[2]+t[4])
  mat<-rbind(mat,c(tpr,fpr))
  
}
colnames(mat)<-c("tpr","fpr")


tree_good<-predict(ftree,test.score,type="vector")[,2]
tree_good<-as.numeric(tree_good)
vec<-vector()

for (i in p){
  pred_tree<-ifelse(tree_good>i,"good","bad")
  t1<-table(test.score$good_bad,factor(pred_tree,labels = c("bad","good"),levels=c("bad","good")))
  tpr1<-t1[1]/(t1[1]+t1[3])
  fpr1<-t1[2]/(t1[2]+t1[4])
  vec<-rbind(vec,c(tpr1,fpr1))
  
}



plot(mat[,2],mat[,1],col="red",type="l",xlab = "FPR",ylab="TPR",
     main = "ROC curves",xlim = c(0,1))
lines(vec[,2],vec[,1],col="blue")
#add legend
legend(0.8,0.75,legend = c("naive","tree"),col=c("blue","red"),pch=15,
       title=" models", bg="lightblue")


df<-read.csv2("state.csv")
  
for (i in 2:6){
  df[,i]<-as.numeric(gsub(",",".",df[,i]))
}


ord_df<-df[order(df[,"MET"]),]


poly_fit <- lm(EX ~ poly(MET, 8), data = ord_df)
plot(ord_df$MET,ord_df$EX,col="black")
lines(ord_df$MET,poly_fit$fitted.values,col="red")



tree_model<-tree(EX~MET,data=ord_df,control=tree.control(nobs=nrow(ord_df),minsize = 8))
set.seed(12345)
cv_tree<-cv.tree(tree_model)  
cv_tree$size[which(cv_tree$dev==min(cv_tree$dev))]

par(mfrow=c(1,2))
plot(cv_tree$size, cv_tree$dev, type="b",col="red") 
logk<-log(cv_tree$k)
plot(logk, cv_tree$dev,type="b", col="red") 


best_tree<-prune.tree(tree_model,best=3)

y_tree<-predict(best_tree,ord_df)
par(mfrow=c(1,3))
plot(ord_df$EX,col="blue")   #plot of the original data
points(y_tree,col="red")
hist(abs(y_tree-ord_df$EX)) 
plot(ord_df$MET,ord_df$EX, pch=19, col="black")
partition.tree(best_tree, label="tree", add=TRUE)


library(boot)


# computing bootstrap samples
f=function(data, ind){
  data1=data[ind,]# extract bootstrap sample
  tree_mod<-tree(EX~MET,data=data1,control=tree.control(nobs=nrow(data1),minsize=8))
  p_tree<-prune.tree(tree_mod,best=3)
  #predict values for all Area values from the original data
  pred_EX=predict(p_tree,newdata=ord_df)
  return(pred_EX)
}
res=boot(ord_df, f, R=1000) #make bootstrap

e=envelope(res) #compute confidence bands

plot(ord_df$MET, ord_df$EX, pch=21, bg="orange")
points(ord_df$MET,y_tree,type="l") #plot fitted line
#plot cofidence bands
points(ord_df$MET,e$point[2,], type="l", col="blue")
points(ord_df$MET,e$point[1,], type="l", col="blue")



rng=function(data, mle) {
  data1=data.frame(EX=data$EX, MET=data$MET)
  n=length(data$EX)
  #generate new Price
  data1$EX=rnorm(n,predict(mle,data=data1),sd(residuals(mle)))
  return(data1)
}

f1=function(data1){

  tree_mod<-tree(EX~MET,data=data1,control=tree.control(nobs=nrow(data1),minsize=8))
  p_tree<-prune.tree(tree_mod,best=3)
  #predict values for all Area values from the original data
  pred_EX=predict(p_tree,newdata=ord_df)
  return(pred_EX)
}

f2=function(data1){
  tree_mod<-tree(EX~MET,data=data1,control=tree.control(nobs=nrow(data1),minsize=8))
  p_tree<-prune.tree(tree_mod,best=3)
  #predict values for all Area values from the original data
  pred_EX=predict(p_tree,newdata=ord_df)
  n=length(ord_df$EX)
  predictedEX=rnorm(n,pred_EX,sd(residuals(best_tree)))
  return(predictedEX)
}



res1=boot(ord_df, statistic=f1, R=1000, mle=best_tree,ran.gen=rng, sim="parametric")

e1=envelope(res1) #compute confidence bands


res2=boot(ord_df,statistic=f2,R=1000,
             mle=best_tree,ran.gen = rng,sim="parametric",parallel = "multicore",ncpus = 4)

e2=envelope(res2)


plot(ord_df$MET, ord_df$EX, pch=21, bg="orange",ylim=c(150,460))
points(ord_df$MET,y_tree,type="l") #plot fitted line
#plot cofidence bands
points(ord_df$MET,e1$point[2,], type="l", col="blue")
points(ord_df$MET,e1$point[1,], type="l", col="blue")
lines(ord_df$MET, e2$point[1, ], lty = 1)
lines(ord_df$MET, e2$point[2, ], lty = 1)



dd<-read.csv2("NIRspectra.csv",sep=";")

prcomp<-prcomp(dd[,1:(ncol(dd)-1)],scale = T)
pca.var<-prcomp$sdev^2     
# calculate percentage of variance of PCAs
pca.var.per<-round(pca.var/sum(pca.var)*100,3)

print("The percentage of variance for feature space ")
pca.var.per

library(RColorBrewer)
par(mfrow=c(1,2))

barplot(pca.var.per[1:14],names.arg=c("PCA1","PCA2","PCA3","PCA4","PCA5","PCA6","PCA7","PCA8","PCA9","PCA10","PCA11","PCA12","PCA13","PCA14"),
        col=brewer.pal(8, "Set2"))

plot(cumsum(pca.var.per), xlab = "Principal Component",
     ylab = "Proportion of Variance Explained",
     type = "b")



plot(prcomp$x[,1:2], col = "blue",xlab = paste0("PCA1 ",pca.var.per[1],"%"),
     ylab=paste0("PCA2 ",pca.var.per[2],"%"))
abline(v=0)#vertical line 
abline(h=0)#horizontal line

U=prcomp$rotation
par(mfrow=c(1,2))
plot(U[,1], main="Traceplot, PC1")   #trace plot PCA1
plot(U[,2],main="Traceplot, PC2")    #trace plots PCA2


library(fastICA)
set.seed(12345)
ica<-fastICA(dd[,1:(ncol(dd)-1)], 2, alg.typ = "parallel", fun = "logcosh", alpha = 1,
        method = "R", row.norm = FALSE, maxit = 200, tol = 0.0001, verbose = F)

W<-ica$K%*%ica$W

par(mfrow=c(1,2))
#trace plots for ica 2
plot(W[,1],main="ICA1")
#trace plots for ica 1
plot(W[,2],main="ICA2")

plot(ica$S, main = "ICA components",xlab="ICA1",ylab="ICA2",col="blue")
abline(v=0)#vertical line 
abline(h=0)#horizontal line




##lda lab2 assignment 1
crabs<-read.csv("australian-crabs.csv")

plot(crabs$CL,crabs$RW,col=crabs$sex,pch=21)
#2

lda.fit<-lda(sex~CL+RW,data=crabs)

preds.lda<-predict(lda.fit,crabs)


plot(crabs$CL,crabs$RW,col=preds.lda$class)
legend(15, 20, pch=12, col=c("red", "black"), c("Male", "Female"), cex=.8)

mean(crabs$sex!=preds.lda$class)
1-mean(crabs$sex!=preds.lda$class)
#3

lda.fit2<-lda(sex ~ CL+RW, crabs, prior = c(0.1,0.9))

preds.lda2 = predict(lda.fit2, data = crabs, type="class")

plot(crabs$CL,crabs$RW,col=preds.lda2$class)
legend(15, 20, pch=12, col=c("red", "black"), c("Male", "Female"), cex=.8)

mean(crabs$sex!=preds.lda2$class)
1-mean(crabs$sex!=preds.lda2$class)

#4
logistic<-glm(sex~CL+RW,data=crabs,family = binomial("logit"))

log_preds<-predict(logistic,newdata = crabs[,-2],type="response")

log_preds<-ifelse(log_preds>0.1,"Male","Female")

mean(crabs$sex!=log_preds)



slope <- coef(logistic)[2]/(-coef(logistic)[3])
intercept <- coef(logistic)[1]/(-coef(logistic)[3])

plot(crabs$CL,crabs$RW,col=as.factor(log_preds))
abline(intercept , slope)
legend(15, 20, pch=12, col=c("red", "black"), c("Male", "Female"), cex=.8)


##


set.seed(12345)
data<-readxl::read_xlsx("influenza.xlsx")


plot(data$Time,data$Mortality,type="l",col="red",ylim = c(0,2800))
lines(data$Time,data$Influenza,col="blue")
legend(2001,1000, legend=c("Mortality", "Infuenza"),
       col=c("red", "blue"), cex=0.8,lty = 1)

library(mgcv)
library(akima)
library(plotly)

spline_fit<-gam(Mortality~Year+s(Week,k=length(unique(data$Week))),data=data,method="GCV.Cp")

s=interp(data$Year,data$Week, fitted(spline_fit))
plot_ly(x=~s$x, y=~s$y, z=~s$z, type="surface")

spline_preds<-predict(spline_fit,data[,-4])

plot(data$Time,data$Mortality,type="l",col="green",
     main="Fitted and Predicted Mortality vs Time")
lines(data$Time,spline_preds,col="red")
legend(2002,2500, legend=c("Fitted", "Predictions"),
       col=c("green", "red"), cex=0.8,lty = 1)




fit_low<-gam(Mortality~s(Week,k=length(unique(data$Week)),sp=0.00001)+
                           Year, data=data,method="GCV.Cp")

fit_high<-gam(Mortality~s(Week,k=length(unique(data$Week)),sp=100)+
                            Year, data=data,method="GCV.Cp")


preds_low<-predict(fit_low,data[,-4])
preds_high<-predict(fit_high,data[,-4])

par(mfrow=c(1,2))
#plot of preds and fitted high penalty
plot(data$Time,data$Mortality,type="l",col="green",
     main="Plot of high penalty")
lines(data$Time,preds_high,col="red")

#plots of preds and fitted low penalty
plot(data$Time,data$Mortality,type="l",col="green",
     main="Plot of low penalty")
lines(data$Time,preds_low,col="red")


dat<-read.csv2("data.csv",sep=";")
dat$Conference<-as.factor(dat$Conference)
set.seed(12345)
#split data to train and test
ind<-sample(nrow(dat),floor(0.7*nrow(dat)))
dtrain<-dat[ind,]
dtest<-dat[-ind,]

library(pamr)

x <- t(dtrain[,-which(names(dtrain)=="Conference")])
y <- as.factor(dtrain$Conference)
mydata <- list(x=x,y=y,geneid=as.character(1:nrow(x)), genenames=rownames(x))

cen_fit<-pamr.train(mydata)
cen_cv<-pamr.cv(cen_fit,mydata)
tres=cen_cv$threshold[which(cen_cv$error==min(cen_cv$error))]

pamr.plotcen(cen_fit, mydata, threshold=tres)

gene_list<-pamr.listgenes(cen_fit, mydata, threshold=tres, fitcv=cen_cv, genenames=T)

nrow(gene_list)

gene_list[1:10,2]

y_test<-t(dtest[,-which(names(dtest)=="Conference")])
cen_preds_test<-pamr.predict(cen_fit,newx=y_test,threshold=tres,type="class")

mean(cen_preds_test!=dtest$Conference)


features<-dtrain[,-which(names(dtrain) == "Conference")]
responses<-as.factor(dtrain$Conference)

library(glmnet)
set.seed(12345)
elastic<-cv.glmnet(as.matrix(features),responses,family="binomial",alpha=0.5)

fit_test<-as.matrix(dtest[,-which(names(dtest)=="Conference")])
#make predictions using lambda.min
elastic_pred<-predict(elastic,fit_test,type="class",s="lambda.1se")
mean(dtest$Conference!=elastic_pred)

length(coef(elastic,s=elastic$lambda.1se)@x)


library(kernlab)

svm.fit<-ksvm(as.matrix(features),responses,kernel="vanilladot")
svm_pred<-predict(svm.fit,fit_test,type="response")

mean(svm_pred!=dtest$Conference)

length(coef(svm.fit)[[1]])

