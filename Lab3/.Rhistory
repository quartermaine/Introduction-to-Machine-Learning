timesf<-as.POSIXct(times,format="%H:%M:%S")
pred_date<-as.POSIXct( date1 , format = "%Y-%m-%d")
st$date<-as.POSIXct(st$date,format="%Y-%m-%d")
st$time<-as.POSIXct(st$time,format="%H:%M:%S")
st_filtered<-st[st$date< pred_date ,]
d1<-distm(st_filtered[,c("longitude","latitude")], c(b,a),fun=distHaversine)
d2<-as.numeric(difftime(pred_date ,st_filtered$date,units = "days"))
func <-function( time ,h){
dist <- as.numeric(difftime(st_filtered$time,time , units="hours"))
dist [dist >12] <- 24 - dist [dist >12]
exp(-(dist/h)^2)
}
k1<-exp(-(d1/h_distance)^2)
k2<-exp(-(d2/h_date)^2)
for(i in 1:length(timesf)){
k3<-func(timesf[i],h_time)
K<-as.vector(k1)+as.vector(k2)+as.vector(k3)
temp[i]<-sum(K*st_filtered$air_temperature)/sum(K)
}
temp_mult<-vector(length=length(times))
for(i in 1:length(timesf)){
k3<-func(timesf[i],h_time)
K1<-as.vector(k1)*as.vector(k2)*as.vector(k3)
temp_mult[i]<-sum(K1*st_filtered$air_temperature)/sum(K1)
}
plot(timesf,temp, type="o",col="blue",main="Linkoping '2013-08-23' Sum kernel",ylim=c(3,15))
lines(timesf,temp_mult,type="o",col="red")
legend("topright", legend=c("Sum", "Product"), col=c("blue", "red"),lty = 1)
stations <- read.csv("stations.csv",stringsAsFactors = F,fileEncoding = "latin1")
temps <- read.csv("temps50k.csv",stringsAsFactors = F)
st <- merge(stations,temps,by="station_number")
h_distance <- 30000        # These three values are up to the students
h_date <-25
h_time <-5
a <- 58.4137 #latitude # The point to predict (up to the students)
b <- 15.6235  #logitude
date1 <- "2013-07-22" # The date to predict (up to the students)
times <- c("04:00:00", "06:00:00","08:00:00" ,"10:00:00","12:00:00","14:00:00",
"16:00:00","18:00:00","20:00:00","22:00:00","24:00:00")
temp <- vector(length=length(times))
# Studentsâ code here
timesf<-as.POSIXct(times,format="%H:%M:%S")
pred_date<-as.POSIXct( date1 , format = "%Y-%m-%d")
st$date<-as.POSIXct(st$date,format="%Y-%m-%d")
st$time<-as.POSIXct(st$time,format="%H:%M:%S")
st_filtered<-st[st$date< pred_date ,]
d1<-distm(st_filtered[,c("longitude","latitude")], c(b,a),fun=distHaversine)
d2<-as.numeric(difftime(pred_date ,st_filtered$date,units = "days"))
func <-function( time ,h){
dist <- as.numeric(difftime(st_filtered$time,time , units="hours"))
dist [dist >12] <- 24 - dist [dist >12]
exp(-(dist/h)^2)
}
k1<-exp(-(d1/h_distance)^2)
k2<-exp(-(d2/h_date)^2)
for(i in 1:length(timesf)){
k3<-func(timesf[i],h_time)
K<-as.vector(k1)+as.vector(k2)+as.vector(k3)
temp[i]<-sum(K*st_filtered$air_temperature)/sum(K)
}
temp_mult<-vector(length=length(times))
for(i in 1:length(timesf)){
k3<-func(timesf[i],h_time)
K1<-as.vector(k1)*as.vector(k2)*as.vector(k3)
temp_mult[i]<-sum(K1*st_filtered$air_temperature)/sum(K1)
}
plot(timesf,temp, type="o",col="blue",main="Linkoping '2013-08-23' Sum kernel",ylim=c(3,20))
lines(timesf,temp_mult,type="o",col="red")
legend("topright", legend=c("Sum", "Product"), col=c("blue", "red"),lty = 1)
stations <- read.csv("stations.csv",stringsAsFactors = F,fileEncoding = "latin1")
temps <- read.csv("temps50k.csv",stringsAsFactors = F)
st <- merge(stations,temps,by="station_number")
h_distance <- 30000        # These three values are up to the students
h_date <-25
h_time <-5
a <- 58.4137 #latitude # The point to predict (up to the students)
b <- 15.6235  #logitude
date1 <- "2013-07-24" # The date to predict (up to the students)
times <- c("04:00:00", "06:00:00","08:00:00" ,"10:00:00","12:00:00","14:00:00",
"16:00:00","18:00:00","20:00:00","22:00:00","24:00:00")
temp <- vector(length=length(times))
# Studentsâ code here
timesf<-as.POSIXct(times,format="%H:%M:%S")
pred_date<-as.POSIXct( date1 , format = "%Y-%m-%d")
st$date<-as.POSIXct(st$date,format="%Y-%m-%d")
st$time<-as.POSIXct(st$time,format="%H:%M:%S")
st_filtered<-st[st$date< pred_date ,]
d1<-distm(st_filtered[,c("longitude","latitude")], c(b,a),fun=distHaversine)
d2<-as.numeric(difftime(pred_date ,st_filtered$date,units = "days"))
func <-function( time ,h){
dist <- as.numeric(difftime(st_filtered$time,time , units="hours"))
dist [dist >12] <- 24 - dist [dist >12]
exp(-(dist/h)^2)
}
k1<-exp(-(d1/h_distance)^2)
k2<-exp(-(d2/h_date)^2)
for(i in 1:length(timesf)){
k3<-func(timesf[i],h_time)
K<-as.vector(k1)+as.vector(k2)+as.vector(k3)
temp[i]<-sum(K*st_filtered$air_temperature)/sum(K)
}
temp_mult<-vector(length=length(times))
for(i in 1:length(timesf)){
k3<-func(timesf[i],h_time)
K1<-as.vector(k1)*as.vector(k2)*as.vector(k3)
temp_mult[i]<-sum(K1*st_filtered$air_temperature)/sum(K1)
}
plot(timesf,temp, type="o",col="blue",main="Linkoping '2013-08-23' Sum kernel",ylim=c(3,20))
lines(timesf,temp_mult,type="o",col="red")
legend("topright", legend=c("Sum", "Product"), col=c("blue", "red"),lty = 1)
stations <- read.csv("stations.csv",stringsAsFactors = F,fileEncoding = "latin1")
temps <- read.csv("temps50k.csv",stringsAsFactors = F)
st <- merge(stations,temps,by="station_number")
h_distance <- 30000        # These three values are up to the students
h_date <-25
h_time <-5
a <- 58.4137 #latitude # The point to predict (up to the students)
b <- 15.6235  #logitude
date1 <- "2013-08-27" # The date to predict (up to the students)
times <- c("04:00:00", "06:00:00","08:00:00" ,"10:00:00","12:00:00","14:00:00",
"16:00:00","18:00:00","20:00:00","22:00:00","24:00:00")
temp <- vector(length=length(times))
# Studentsâ code here
timesf<-as.POSIXct(times,format="%H:%M:%S")
pred_date<-as.POSIXct( date1 , format = "%Y-%m-%d")
st$date<-as.POSIXct(st$date,format="%Y-%m-%d")
st$time<-as.POSIXct(st$time,format="%H:%M:%S")
st_filtered<-st[st$date< pred_date ,]
d1<-distm(st_filtered[,c("longitude","latitude")], c(b,a),fun=distHaversine)
d2<-as.numeric(difftime(pred_date ,st_filtered$date,units = "days"))
func <-function( time ,h){
dist <- as.numeric(difftime(st_filtered$time,time , units="hours"))
dist [dist >12] <- 24 - dist [dist >12]
exp(-(dist/h)^2)
}
k1<-exp(-(d1/h_distance)^2)
k2<-exp(-(d2/h_date)^2)
for(i in 1:length(timesf)){
k3<-func(timesf[i],h_time)
K<-as.vector(k1)+as.vector(k2)+as.vector(k3)
temp[i]<-sum(K*st_filtered$air_temperature)/sum(K)
}
temp_mult<-vector(length=length(times))
for(i in 1:length(timesf)){
k3<-func(timesf[i],h_time)
K1<-as.vector(k1)*as.vector(k2)*as.vector(k3)
temp_mult[i]<-sum(K1*st_filtered$air_temperature)/sum(K1)
}
plot(timesf,temp, type="o",col="blue",main="Linkoping '2013-08-23' Sum kernel",ylim=c(3,20))
lines(timesf,temp_mult,type="o",col="red")
legend("topright", legend=c("Sum", "Product"), col=c("blue", "red"),lty = 1)
stations <- read.csv("stations.csv",stringsAsFactors = F,fileEncoding = "latin1")
temps <- read.csv("temps50k.csv",stringsAsFactors = F)
st <- merge(stations,temps,by="station_number")
h_distance <- 30000        # These three values are up to the students
h_date <-25
h_time <-5
a <- 58.4137 #latitude # The point to predict (up to the students)
b <- 15.6235  #logitude
date1 <- "2013-08-27" # The date to predict (up to the students)
times <- c("04:00:00", "06:00:00","08:00:00" ,"10:00:00","12:00:00","14:00:00",
"16:00:00","18:00:00","20:00:00","22:00:00","24:00:00")
temp <- vector(length=length(times))
# Studentsâ code here
timesf<-as.POSIXct(times,format="%H:%M:%S")
pred_date<-as.POSIXct( date1 , format = "%Y-%m-%d")
st$date<-as.POSIXct(st$date,format="%Y-%m-%d")
st$time<-as.POSIXct(st$time,format="%H:%M:%S")
st_filtered<-st[st$date< pred_date ,]
d1<-distm(st_filtered[,c("longitude","latitude")], c(b,a),fun=distHaversine)
d2<-as.numeric(difftime(pred_date ,st_filtered$date,units = "days"))
func <-function( time ,h){
dist <- as.numeric(difftime(st_filtered$time,time , units="hours"))
dist [dist >12] <- 24 - dist [dist >12]
exp(-(dist/h)^2)
}
k1<-exp(-(d1/h_distance)^2)
k2<-exp(-(d2/h_date)^2)
for(i in 1:length(timesf)){
k3<-func(timesf[i],h_time)
K<-as.vector(k1)+as.vector(k2)+as.vector(k3)
temp[i]<-sum(K*st_filtered$air_temperature)/sum(K)
}
temp_mult<-vector(length=length(times))
for(i in 1:length(timesf)){
k3<-func(timesf[i],h_time)
K1<-as.vector(k1)*as.vector(k2)*as.vector(k3)
temp_mult[i]<-sum(K1*st_filtered$air_temperature)/sum(K1)
}
plot(timesf,temp, type="o",col="blue",main="Linkoping '2013-08-27' Sum kernel",ylim=c(3,20))
lines(timesf,temp_mult,type="o",col="red")
legend("topright", legend=c("Sum", "Product"), col=c("blue", "red"),lty = 1)
stations <- read.csv("stations.csv",stringsAsFactors = F,fileEncoding = "latin1")
temps <- read.csv("temps50k.csv",stringsAsFactors = F)
st <- merge(stations,temps,by="station_number")
h_distance <- 30000        # These three values are up to the students
h_date <-25
h_time <-5
a <- 58.4137 #latitude # The point to predict (up to the students)
b <- 15.6235  #logitude
date1 <- "2013-12-24" # The date to predict (up to the students)
times <- c("04:00:00", "06:00:00","08:00:00" ,"10:00:00","12:00:00","14:00:00",
"16:00:00","18:00:00","20:00:00","22:00:00","24:00:00")
temp <- vector(length=length(times))
# Studentsâ code here
timesf<-as.POSIXct(times,format="%H:%M:%S")
pred_date<-as.POSIXct( date1 , format = "%Y-%m-%d")
st$date<-as.POSIXct(st$date,format="%Y-%m-%d")
st$time<-as.POSIXct(st$time,format="%H:%M:%S")
st_filtered<-st[st$date< pred_date ,]
d1<-distm(st_filtered[,c("longitude","latitude")], c(b,a),fun=distHaversine)
d2<-as.numeric(difftime(pred_date ,st_filtered$date,units = "days"))
func <-function( time ,h){
dist <- as.numeric(difftime(st_filtered$time,time , units="hours"))
dist [dist >12] <- 24 - dist [dist >12]
exp(-(dist/h)^2)
}
k1<-exp(-(d1/h_distance)^2)
k2<-exp(-(d2/h_date)^2)
for(i in 1:length(timesf)){
k3<-func(timesf[i],h_time)
K<-as.vector(k1)+as.vector(k2)+as.vector(k3)
temp[i]<-sum(K*st_filtered$air_temperature)/sum(K)
}
temp_mult<-vector(length=length(times))
for(i in 1:length(timesf)){
k3<-func(timesf[i],h_time)
K1<-as.vector(k1)*as.vector(k2)*as.vector(k3)
temp_mult[i]<-sum(K1*st_filtered$air_temperature)/sum(K1)
}
plot(timesf,temp, type="o",col="blue",main="Linkoping '2013-08-23' Sum kernel",ylim=c(3,20))
lines(timesf,temp_mult,type="o",col="red")
legend("topright", legend=c("Sum", "Product"), col=c("blue", "red"),lty = 1)
stations <- read.csv("stations.csv",stringsAsFactors = F,fileEncoding = "latin1")
temps <- read.csv("temps50k.csv",stringsAsFactors = F)
st <- merge(stations,temps,by="station_number")
h_distance <- 30000        # These three values are up to the students
h_date <-25
h_time <-5
a <- 58.4137 #latitude # The point to predict (up to the students)
b <- 15.6235  #logitude
date1 <- "2013-12-24" # The date to predict (up to the students)
times <- c("04:00:00", "06:00:00","08:00:00" ,"10:00:00","12:00:00","14:00:00",
"16:00:00","18:00:00","20:00:00","22:00:00","24:00:00")
temp <- vector(length=length(times))
# Studentsâ code here
timesf<-as.POSIXct(times,format="%H:%M:%S")
pred_date<-as.POSIXct( date1 , format = "%Y-%m-%d")
st$date<-as.POSIXct(st$date,format="%Y-%m-%d")
st$time<-as.POSIXct(st$time,format="%H:%M:%S")
st_filtered<-st[st$date< pred_date ,]
d1<-distm(st_filtered[,c("longitude","latitude")], c(b,a),fun=distHaversine)
d2<-as.numeric(difftime(pred_date ,st_filtered$date,units = "days"))
func <-function( time ,h){
dist <- as.numeric(difftime(st_filtered$time,time , units="hours"))
dist [dist >12] <- 24 - dist [dist >12]
exp(-(dist/h)^2)
}
k1<-exp(-(d1/h_distance)^2)
k2<-exp(-(d2/h_date)^2)
for(i in 1:length(timesf)){
k3<-func(timesf[i],h_time)
K<-as.vector(k1)+as.vector(k2)+as.vector(k3)
temp[i]<-sum(K*st_filtered$air_temperature)/sum(K)
}
temp_mult<-vector(length=length(times))
for(i in 1:length(timesf)){
k3<-func(timesf[i],h_time)
K1<-as.vector(k1)*as.vector(k2)*as.vector(k3)
temp_mult[i]<-sum(K1*st_filtered$air_temperature)/sum(K1)
}
plot(timesf,temp, type="o",col="blue",main="Linkoping '2013-12-24' Sum kernel",ylim=c(-5,5))
lines(timesf,temp_mult,type="o",col="red")
legend("topright", legend=c("Sum", "Product"), col=c("blue", "red"),lty = 1)
stations <- read.csv("stations.csv",stringsAsFactors = F,fileEncoding = "latin1")
temps <- read.csv("temps50k.csv",stringsAsFactors = F)
st <- merge(stations,temps,by="station_number")
h_distance <- 30000        # These three values are up to the students
h_date <-25
h_time <-5
a <- 58.4137 #latitude # The point to predict (up to the students)
b <- 15.6235  #logitude
date1 <- "2013-12-24" # The date to predict (up to the students)
times <- c("04:00:00", "06:00:00","08:00:00" ,"10:00:00","12:00:00","14:00:00",
"16:00:00","18:00:00","20:00:00","22:00:00","24:00:00")
temp <- vector(length=length(times))
# Studentsâ code here
timesf<-as.POSIXct(times,format="%H:%M:%S")
pred_date<-as.POSIXct( date1 , format = "%Y-%m-%d")
st$date<-as.POSIXct(st$date,format="%Y-%m-%d")
st$time<-as.POSIXct(st$time,format="%H:%M:%S")
st_filtered<-st[st$date< pred_date ,]
d1<-distm(st_filtered[,c("longitude","latitude")], c(b,a),fun=distHaversine)
d2<-as.numeric(difftime(pred_date ,st_filtered$date,units = "days"))
func <-function( time ,h){
dist <- as.numeric(difftime(st_filtered$time,time , units="hours"))
dist [dist >12] <- 24 - dist [dist >12]
exp(-(dist/h)^2)
}
k1<-exp(-(d1/h_distance)^2)
k2<-exp(-(d2/h_date)^2)
for(i in 1:length(timesf)){
k3<-func(timesf[i],h_time)
K<-as.vector(k1)+as.vector(k2)+as.vector(k3)
temp[i]<-sum(K*st_filtered$air_temperature)/sum(K)
}
temp_mult<-vector(length=length(times))
for(i in 1:length(timesf)){
k3<-func(timesf[i],h_time)
K1<-as.vector(k1)*as.vector(k2)*as.vector(k3)
temp_mult[i]<-sum(K1*st_filtered$air_temperature)/sum(K1)
}
plot(timesf,temp, type="o",col="blue",main="Linkoping '2013-12-24' Sum kernel",ylim=c(-5,7))
lines(timesf,temp_mult,type="o",col="red")
legend("topright", legend=c("Sum", "Product"), col=c("blue", "red"),lty = 1)
stations <- read.csv("stations.csv",stringsAsFactors = F,fileEncoding = "latin1")
temps <- read.csv("temps50k.csv",stringsAsFactors = F)
st <- merge(stations,temps,by="station_number")
h_distance <- 30000        # These three values are up to the students
h_date <-25
h_time <-5
a <- 58.4137 #latitude # The point to predict (up to the students)
b <- 15.6235  #logitude
date1 <- "2013-12-24" # The date to predict (up to the students)
times <- c("04:00:00", "06:00:00","08:00:00" ,"10:00:00","12:00:00","14:00:00",
"16:00:00","18:00:00","20:00:00","22:00:00","24:00:00")
temp <- vector(length=length(times))
# Studentsâ code here
timesf<-as.POSIXct(times,format="%H:%M:%S")
pred_date<-as.POSIXct( date1 , format = "%Y-%m-%d")
st$date<-as.POSIXct(st$date,format="%Y-%m-%d")
st$time<-as.POSIXct(st$time,format="%H:%M:%S")
st_filtered<-st[st$date< pred_date ,]
d1<-distm(st_filtered[,c("longitude","latitude")], c(b,a),fun=distHaversine)
d2<-as.numeric(difftime(pred_date ,st_filtered$date,units = "days"))
func <-function( time ,h){
dist <- as.numeric(difftime(st_filtered$time,time , units="hours"))
dist [dist >12] <- 24 - dist [dist >12]
exp(-(dist/h)^2)
}
k1<-exp(-(d1/h_distance)^2)
k2<-exp(-(d2/h_date)^2)
for(i in 1:length(timesf)){
k3<-func(timesf[i],h_time)
K<-as.vector(k1)+as.vector(k2)+as.vector(k3)
temp[i]<-sum(K*st_filtered$air_temperature)/sum(K)
}
temp_mult<-vector(length=length(times))
for(i in 1:length(timesf)){
k3<-func(timesf[i],h_time)
K1<-as.vector(k1)*as.vector(k2)*as.vector(k3)
temp_mult[i]<-sum(K1*st_filtered$air_temperature)/sum(K1)
}
plot(timesf,temp, type="o",col="blue",main="Linkoping '2013-12-24' Sum kernel",ylim=c(-2,7))
lines(timesf,temp_mult,type="o",col="red")
legend("topright", legend=c("Sum", "Product"), col=c("blue", "red"),lty = 1)
tail(stations)
head(stations)
# empty the environment
rm(list = ls())
# set.seed
set.seed(1234567890)
# load data set spam
# data is included in the package kernlab
data(spam)
data = spam
# split the data into train, validation and test set
n=dim(data)[1]
id=sample(1:n, floor(n*0.5))
train=data[id,]
id1=setdiff(1:n, id)
set.seed(12345)
id2=sample(id1, floor(n*0.25))
valid=data[id2,]
id3=setdiff(id1,id2)
test=data[id3,]
# create a function
# model selection - find best parameter option
SVM_function = function(train_data, C, valid_data){
# given values
kernel_type = "rbfdot"
problem_type = "C-svc"
# split into x- & y-train
y_train = train_data$type
x_train = train_data[,-ncol(train_data)]
# fit the model with given paramters
svm_fit = ksvm(type~.,
data = train_data,
kernel = kernel_type, # Radial Basis kernel "Gaussian" - default
C = C,
type = problem_type,# classification problem
kpar=list(sigma=0.05)) # sigma inverse kernel width for
# the Radial Basis kernel function "rbfdot" and the Laplacian kernel "laplacedot".
# make predictions for train data on validation data
pred_svm_valid = predict(object = svm_fit,
newdata = valid_data)
# Create confusion matrix
#confusionMatrix(pred, actual)
#cm = confusionMatrix(pred_svm_valid, valid_data[,ncol(valid_data)])
confusion_matrix = table(pred_svm_valid, valid_data$type)
# compute test error
test_error = (confusion_matrix[1,2] + confusion_matrix[2,1])/ sum(confusion_matrix)
results = list("confusion_matrix" = confusion_matrix,
"test_error" = test_error)
# return results
return(results)
}
C05 = SVM_function(train, 0.5, valid)
C05
C1 = SVM_function(train, 1, valid)
C1$confusion_matrix
C5 = SVM_function(train, 5, valid)
C5$confusion_matrix
# create data frame with results
testerror_df = data.frame(
"C=0.5" = C05$test_error,
"C=1" = C1$test_error,
"C=5" = C5$test_error
)
#rownames(testerror_df) = "Test error"
# print table solutions
knitr::kable(testerror_df, caption = "Misclassification Table")
# put the test and validation data together
test_valid = rbind(test,valid)
# train model with train & validation data
svm_fit_C1_best = ksvm(type~.,
data = train,
kernel = "rbfdot",
C = 1,
type = "C-svc",
kpar=list(sigma=0.05))
# make prediction - test data
pred_svm_fit_C1_best = predict(object = svm_fit_C1_best,
newdata = test)
cm_pred_svm_fit_C1_best = table(test$type, pred_svm_fit_C1_best)
# generalization error
generalizationerror_cm_pred_svm_fit_C1_best = (cm_pred_svm_fit_C1_best[1,2] + cm_pred_svm_fit_C1_best[2,1])/ sum(cm_pred_svm_fit_C1_best)
# output
cm_pred_svm_fit_C1_best
generalizationerror_cm_pred_svm_fit_C1_best
# show the code to the user
# train model with the whole data
svm_fit = ksvm(type~.,
data = spam,
kernel = "rbfdot",
C = 1,
type = "C-svc",
kpar=list(sigma=0.05))
svm_fit
#
# This is a Shiny web application. You can run the application by clicking
# the 'Run App' button above.
#
# Find out more about building applications with Shiny here:
#
#    http://shiny.rstudio.com/
#
library(shiny)
library(httr)
library(jpeg)
library(RCurl)
library(jsonlite)
library(shinythemes)
#library(imager)
key<-"eH45R9w40U4mHE79ErvPWMtaANJlDwNaEtGx3vLF"
url<-"https://api.nasa.gov/planetary/apod?date="
ui <- fluidPage(theme = shinytheme("cerulean"),
# Application title
titlePanel("Nasa API"),
# Sidebar with a slider input for number of bins
sidebarLayout(
sidebarPanel(
helpText("Wellcome to Nasa search API ",
"enter a date in YYYY-MM-DD to search for picture"),
textInput("date", label="Date input",
value = "Enter date..."),
actionButton("go", "Search")
),
mainPanel(
uiOutput("img")
)
)
)
server <- function(input, output,session) {
query<-eventReactive(input$go,{
input$date
})
output$img <- renderUI({
nasa_url<-paste0(url,query(),"&api_key=",key)
# A temp file to save the output.
# This file will be removed later by renderImage
response<-getURLContent(nasa_url)
json<-fromJSON(response)
img_url<-json$url
img_title<-json$title
img_exp<-json$explanation
#temp<-tempfile(pattern = "file", fileext = ".jpg")
#download.file(img_url,temp,mode="wb")
#jj <- readJPEG(temp,native=TRUE)
#plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
#rasterImage(jj,0,0,1,1)
#im<-load.image(temp) #use this with library(imager)
#plot(im)             #use this with library(imager)
list(tags$h2(img_title),tags$img(src = img_url,width = "500px", height = "400px"),tags$hr(),tags$p(img_exp))
})
}
# Run the application
shinyApp(ui = ui, server = server)
runApp('~/MyShiny/Nasa-API/Nasa-API')
install.packages('rlang')
runApp('~/MyShiny/Nasa-API/Nasa-API')
runApp('~/MyShiny/NY-API')
